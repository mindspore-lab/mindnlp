"""
OCR API ç‹¬ç«‹å¯åŠ¨è„šæœ¬
å®Œå…¨ç‹¬ç«‹äº mindnlp å…¶ä»–æ¨¡å—,é¿å…è§¦å‘ mindspore ä¾èµ–
"""

import os
import sys
import subprocess

# è®¾ç½®é•œåƒç«™ç‚¹ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨ä»»ä½•å¯¼å…¥ä¹‹å‰ï¼‰
os.environ.setdefault('HF_ENDPOINT', 'https://hf-mirror.com')
os.environ.setdefault('HF_HUB_ENDPOINT', 'https://hf-mirror.com')

# æ³¨æ„: ä¸åœ¨è¿™é‡Œè®¾ç½®ç¦»çº¿æ¨¡å¼,ç­‰æ¨¡å‹ä¸‹è½½å®Œæˆåå†è®¾ç½®
# è¿™æ ·å¯ä»¥åœ¨éœ€è¦æ—¶ä¸‹è½½æ¨¡å‹,è¿è¡Œæ—¶ä½¿ç”¨ç¦»çº¿æ¨¡å¼

# å°† src ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))
if src_dir not in sys.path:
    sys.path.insert(0, src_dir)


def check_and_install_dependencies():
    """æ£€æµ‹å¹¶è‡ªåŠ¨å®‰è£…ç¼ºå¤±çš„ä¾èµ–"""
    # æ ‡å‡†ä¾èµ–
    required_packages = {
        'torch': 'torch>=2.4.0',
            'torchvision': 'torchvision>=0.19.0',
            'transformers': 'transformers>=4.37.0',
            'fastapi': 'fastapi>=0.109.0',
            'uvicorn': 'uvicorn[standard]>=0.27.0',
            'PIL': 'pillow>=10.0.0',
            'pydantic_settings': 'pydantic-settings>=2.0.0',
            'requests': 'requests>=2.31.0',
            'yaml': 'pyyaml>=6.0',
        }
    
    missing_packages = []
    
    print("æ­£åœ¨æ£€æŸ¥ä¾èµ–...")
    for package, install_name in required_packages.items():
        try:
            __import__(package)
            print(f"  âœ“ {package}")
        except ImportError:
            print(f"  âœ— {package} (ç¼ºå¤±)")
            missing_packages.append(install_name)
    
    if missing_packages:
        print(f"\nå‘ç° {len(missing_packages)} ä¸ªç¼ºå¤±çš„ä¾èµ–åŒ…")
        print("æ­£åœ¨è‡ªåŠ¨å®‰è£…...")
        
        try:
            # ä½¿ç”¨å½“å‰ Python è§£é‡Šå™¨å®‰è£…ä¾èµ–
            cmd = [sys.executable, '-m', 'pip', 'install'] + missing_packages
            subprocess.check_call(cmd)
            print("âœ“ ä¾èµ–å®‰è£…å®Œæˆ")
            return True
        except subprocess.CalledProcessError as e:
            print(f"âœ— ä¾èµ–å®‰è£…å¤±è´¥: {e}")
            print("\nè¯·æ‰‹åŠ¨å®‰è£…ä¾èµ–:")
            print(f"  pip install {' '.join(missing_packages)}")
            return False
    else:
        print("âœ“ æ‰€æœ‰ä¾èµ–å·²æ»¡è¶³")
        return True


# æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–
if not check_and_install_dependencies():
    print("\næ— æ³•ç»§ç»­å¯åŠ¨æœåŠ¡ï¼Œè¯·å…ˆå®‰è£…ä¾èµ–")
    sys.exit(1)

print("")  # ç©ºè¡Œåˆ†éš”

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['NO_PROXY'] = '*'
os.environ['HTTP_PROXY'] = ''
os.environ['HTTPS_PROXY'] = ''
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# ç›´æ¥å¯¼å…¥ OCR å­æ¨¡å—ï¼Œé¿å… mindnlp.__init__.py
# ä½¿ç”¨ sys.modules æŠ€å·§æ¥é¿å… mindnlp.__init__.py çš„æ‰§è¡Œ
import types

# åˆ›å»ºä¸€ä¸ªç©ºçš„ mindnlp æ¨¡å—
mindnlp = types.ModuleType('mindnlp')
mindnlp.__path__ = [os.path.join(src_dir, 'mindnlp')]
sys.modules['mindnlp'] = mindnlp

# åˆ›å»ºç©ºçš„ mindnlp.ocr æ¨¡å—
mindnlp_ocr = types.ModuleType('mindnlp.ocr')
mindnlp_ocr.__path__ = [current_dir]
sys.modules['mindnlp.ocr'] = mindnlp_ocr

# ç°åœ¨å¯ä»¥å®‰å…¨å¯¼å…¥ OCR å­æ¨¡å—äº†
from mindnlp.ocr.api.app import create_app
import uvicorn


def check_model_exists(model_name: str) -> bool:
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½åˆ°æœ¬åœ°
    
    Args:
        model_name: æ¨¡å‹åç§°ï¼Œå¦‚ Qwen/Qwen2-VL-2B-Instruct
        
    Returns:
        bool: æ¨¡å‹æ˜¯å¦å­˜åœ¨
    """
    from pathlib import Path
    
    # è·å– HuggingFace ç¼“å­˜ç›®å½•
    cache_dir = os.environ.get('HF_HOME') or os.environ.get('TRANSFORMERS_CACHE') or \
                Path.home() / '.cache' / 'huggingface'
    
    # è½¬æ¢æ¨¡å‹åç§°ä¸ºç¼“å­˜ç›®å½•æ ¼å¼
    model_cache_name = f"models--{model_name.replace('/', '--')}"
    model_path = Path(cache_dir) / model_cache_name
    
    # æ£€æŸ¥ç›®å½•å’Œå¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not model_path.exists():
        return False
    
    snapshots_dir = model_path / "snapshots"
    if not snapshots_dir.exists():
        return False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¿«ç…§ç›®å½•(è‡³å°‘æœ‰ä¸€ä¸ªå®Œæ•´ä¸‹è½½çš„ç‰ˆæœ¬)
    snapshot_dirs = list(snapshots_dir.iterdir())
    if not snapshot_dirs:
        return False
    
    # æ£€æŸ¥æœ€æ–°çš„å¿«ç…§æ˜¯å¦åŒ…å«å¿…è¦æ–‡ä»¶
    latest_snapshot = snapshot_dirs[-1]
    required_files = ['config.json', 'tokenizer_config.json']
    
    for file in required_files:
        if not (latest_snapshot / file).exists():
            return False
    
    return True


def download_model(model_name: str):
    """ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
    
    Args:
        model_name: æ¨¡å‹åç§°
    """
    print(f"\n{'='*60}")
    print(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹: {model_name}")
    print(f"è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´,è¯·è€å¿ƒç­‰å¾…...")
    print(f"{'='*60}\n")
    
    # ç¡®ä¿ä½¿ç”¨é•œåƒç«™ç‚¹(åœ¨æ–‡ä»¶å¼€å¤´å·²è®¾ç½®,è¿™é‡Œå†æ¬¡ç¡®è®¤)
    os.environ.pop('HF_HUB_OFFLINE', None)
    os.environ.pop('TRANSFORMERS_OFFLINE', None)
    
    print(f"ğŸ“¡ ä½¿ç”¨é•œåƒç«™ç‚¹: {os.environ.get('HF_HUB_ENDPOINT', 'https://hf-mirror.com')}\n")
    
    try:
        from transformers import AutoTokenizer, AutoConfig, AutoModel
        
        # ä¸‹è½½é…ç½®
        print("ğŸ“¥ ä¸‹è½½æ¨¡å‹é…ç½®...")
        config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)
        
        # ä¸‹è½½tokenizer/processor
        print("ğŸ“¥ ä¸‹è½½tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        
        # ä¸‹è½½æ¨¡å‹æƒé‡
        print("ğŸ“¥ ä¸‹è½½æ¨¡å‹æƒé‡...")
        model = AutoModel.from_pretrained(
            model_name,
            torch_dtype='auto',
            device_map='cpu',  # å…ˆä¸‹è½½åˆ°CPUé¿å…æ˜¾å­˜é—®é¢˜
            low_cpu_mem_usage=True,
            trust_remote_code=True
        )
        
        print(f"\nâœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_name}")
        del model  # é‡Šæ”¾å†…å­˜
                
    except Exception as e:
        print(f"\nâŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒHuggingFaceè®¿é—®")
        raise


def main():
    """å¯åŠ¨ API æœåŠ¡"""
    # åŠ è½½é…ç½®
    from mindnlp.ocr.config.settings import get_settings
    settings = get_settings()
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨,ä¸å­˜åœ¨åˆ™ä¸‹è½½
    print(f"ğŸ” æ£€æŸ¥æ¨¡å‹: {settings.default_model}")
    if not check_model_exists(settings.default_model):
        print(f"âš ï¸  æ¨¡å‹æœªæ‰¾åˆ°,å¼€å§‹ä¸‹è½½...")
        download_model(settings.default_model)
    else:
        print(f"âœ… æ¨¡å‹å·²å­˜åœ¨,å°†ä½¿ç”¨æœ¬åœ°ç¼“å­˜")
    
    # æ¨¡å‹ä¸‹è½½æˆ–ç¡®è®¤å,è®¾ç½®ç¦»çº¿æ¨¡å¼
    os.environ['HF_HUB_OFFLINE'] = '1'
    os.environ['TRANSFORMERS_OFFLINE'] = '1'
    print("ğŸ”’ å·²å¯ç”¨ç¦»çº¿æ¨¡å¼\n")
    
    # åˆ›å»ºåº”ç”¨
    app = create_app()
    
    # å¯åŠ¨æœåŠ¡å™¨
    print(f"\n{'='*60}")
    print(f"å¯åŠ¨ OCR API æœåŠ¡...")
    print(f"  - Host: {settings.api_host}")
    print(f"  - Port: {settings.api_port}")
    print(f"  - è®¾å¤‡: {settings.device}")
    print(f"  - æ¨¡å‹: {settings.default_model}")
    print(f"  - Mockæ¨¡å¼: {settings.use_mock_engine}")
    print(f"\nğŸ“š API æ–‡æ¡£åœ°å€ (æ¨èä½¿ç”¨):")
    print(f"  - Swagger UI:  http://localhost:{settings.api_port}/api/docs")
    print(f"  - ReDoc:       http://localhost:{settings.api_port}/api/redoc")
    print(f"\nğŸ” API ç«¯ç‚¹:")
    print(f"  - å¥åº·æ£€æŸ¥ (GET):    http://localhost:{settings.api_port}/api/v1/health")
    print(f"  - OCRé¢„æµ‹ (POST):    http://localhost:{settings.api_port}/api/v1/ocr/predict")
    print(f"  - æ‰¹é‡OCR (POST):    http://localhost:{settings.api_port}/api/v1/ocr/predict_batch")
    print(f"  - URL OCR (POST):    http://localhost:{settings.api_port}/api/v1/ocr/predict_url")
    print(f"\nğŸ’¡ æç¤º: POST ç«¯ç‚¹è¯·ä½¿ç”¨ API æ–‡æ¡£é¡µé¢è¿›è¡Œäº¤äº’å¼æµ‹è¯•")
    print(f"{'='*60}\n")
    
    uvicorn.run(
        app,
        host=settings.api_host,
        port=settings.api_port,
        log_level="info"
    )


if __name__ == "__main__":
    main()
