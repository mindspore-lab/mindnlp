# ğŸš€ Mistral MoE åº”ç”¨æ¡ˆä¾‹å¿«é€Ÿå…¥é—¨æŒ‡å—

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [å¿«é€Ÿä½“éªŒ](#å¿«é€Ÿä½“éªŒ)
- [åº”ç”¨æ¡ˆä¾‹è¯¦è§£](#åº”ç”¨æ¡ˆä¾‹è¯¦è§£)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ”§ ç¯å¢ƒå‡†å¤‡

### 1. ç³»ç»Ÿè¦æ±‚

- **Python**: 3.9+
- **å†…å­˜**: 8GB+
- **å­˜å‚¨**: 2GB+

### 2. å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n mistral_moe python=3.9
conda activate mistral_moe

# å®‰è£…MindSpore
pip install mindspore>=2.6.0

# å®‰è£…å…¶ä»–ä¾èµ–
pip install numpy matplotlib
```

### 3. éªŒè¯å®‰è£…

```python
import mindspore
print(f"MindSporeç‰ˆæœ¬: {mindspore.__version__}")

from mindspore import context
context.set_context(mode=context.PYNATIVE_MODE)
print("âœ… ç¯å¢ƒé…ç½®æˆåŠŸï¼")
```

---

## ğŸ¯ å¿«é€Ÿä½“éªŒ

### ä½“éªŒ1: æ™ºèƒ½æ–‡æœ¬æ‘˜è¦

```python
# è¿è¡Œæ™ºèƒ½æ–‡æœ¬æ‘˜è¦ç”Ÿæˆå™¨
python course/code_examples/smart_text_summarizer.py
```

**é¢„æœŸè¾“å‡º:**
```
================================================================================
ğŸ¤– æ™ºèƒ½æ–‡æœ¬æ‘˜è¦ç”Ÿæˆå™¨æ¼”ç¤º
================================================================================
âœ… æ™ºèƒ½æ–‡æœ¬æ‘˜è¦ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ
   - æ¨¡å‹é…ç½®: 512ç»´, 6å±‚
   - MoEä¸“å®¶: 4ä¸ªä¸“å®¶, æ¯tokenä½¿ç”¨2ä¸ª
   - æœ€å¤§é•¿åº¦: 2048

ğŸ“ å¤„ç† news ç±»å‹æ–‡æœ¬...
   åŸæ–‡é•¿åº¦: 274 å­—ç¬¦
   æ‘˜è¦é•¿åº¦: 159 å­—ç¬¦
   ç”Ÿæˆæ—¶é—´: 0.002 ç§’
   è´¨é‡è¯„åˆ†: 0.800
   æ‘˜è¦å†…å®¹: äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨è¿‡å»åå¹´ä¸­å–å¾—äº†çªé£çŒ›è¿›çš„å‘å±•...

ğŸ“Š ç”Ÿæˆä¸“å®¶ä½¿ç”¨åˆ†æå›¾...
ğŸ“Š ä¸“å®¶ä½¿ç”¨åˆ†æå›¾å·²ä¿å­˜: expert_usage_analysis.png
```

### ä½“éªŒ2: ä»£ç ç”ŸæˆåŠ©æ‰‹

```python
# è¿è¡Œä»£ç ç”ŸæˆåŠ©æ‰‹
python course/code_examples/code_generation_assistant.py
```

**é¢„æœŸè¾“å‡º:**
```
================================================================================
ğŸ’» ä»£ç ç”ŸæˆåŠ©æ‰‹æ¼”ç¤º
================================================================================
âœ… ä»£ç ç”ŸæˆåŠ©æ‰‹åˆå§‹åŒ–å®Œæˆ
   - æ¨¡å‹é…ç½®: 512ç»´, 6å±‚
   - MoEä¸“å®¶: 4ä¸ªä¸“å®¶, æ¯tokenä½¿ç”¨2ä¸ª
   - æ”¯æŒè¯­è¨€: Python, JavaScript, Java
   - æœ€å¤§é•¿åº¦: 2048

ğŸ’» ç”Ÿæˆ python function: è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—
   è¯­è¨€: python
   ç±»å‹: function
   ç”Ÿæˆæ—¶é—´: 0.039 ç§’
   è´¨é‡è¯„åˆ†: 0.577
   ä»£ç é•¿åº¦: 72 å­—ç¬¦
   ä»£ç é¢„è§ˆ: def è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—():
    """
    è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—
    """
    # TODO: å®ç°å…·ä½“åŠŸèƒ½
    pass...

ğŸ“Š ç”Ÿæˆä»£ç åˆ†æå›¾...
ğŸ“Š ä»£ç åˆ†æå›¾å·²ä¿å­˜: code_analysis.png
```

### ä½“éªŒ3: MoEè·¯ç”±æ¼”ç¤º

```python
# è¿è¡ŒMoEè·¯ç”±æœºåˆ¶æ¼”ç¤º
python course/code_examples/moe_routing_demo.py
```

**é¢„æœŸè¾“å‡º:**
```
============================================================
MoEè·¯ç”±æœºåˆ¶æ¼”ç¤º
============================================================

Simple Router:
----------------------------------------

è¾“å…¥ç±»å‹: Random Input
  ä¸“å®¶ä½¿ç”¨åˆ†å¸ƒ: [13. 13. 15. 13. 18. 23. 17. 16.]
  æœ€å¸¸ç”¨ä¸“å®¶: 5
  æœ€å°‘ç”¨ä¸“å®¶: 0
  ä½¿ç”¨ç‡æ ‡å‡†å·®: 3.20
å¤„ç†è¾“å…¥: åŸå§‹å½¢çŠ¶=(1, 16, 128), å±•å¹³åå½¢çŠ¶=(16, 128)
å¯è§†åŒ–æ•°æ®å½¢çŠ¶: probs_np=(16, 8), selected_np=(16, 2)
å›¾ç‰‡å·²ä¿å­˜ä¸º: Simple_Router_Random_Input.png
```

---

## ğŸ“š åº”ç”¨æ¡ˆä¾‹è¯¦è§£

### 1. æ™ºèƒ½æ–‡æœ¬æ‘˜è¦ç”Ÿæˆå™¨

#### æ ¸å¿ƒåŠŸèƒ½

```python
from course.code_examples.smart_text_summarizer import SmartTextSummarizer

# åˆå§‹åŒ–
summarizer = SmartTextSummarizer()

# ç”Ÿæˆæ‘˜è¦
text = "è¿™æ˜¯ä¸€æ®µéœ€è¦æ‘˜è¦çš„é•¿æ–‡æœ¬..."
result = summarizer.generate_summary(
    text=text,
    summary_type="news",  # å¯é€‰: news, tech, literature, academic, general
    max_summary_length=200
)

print(f"æ‘˜è¦: {result['summary']}")
print(f"è´¨é‡è¯„åˆ†: {result['quality_metrics']['quality_score']}")
```

#### æ”¯æŒçš„åŠŸèƒ½

- âœ… **å¤šç±»å‹æ‘˜è¦**: æ–°é—»ã€ç§‘æŠ€ã€æ–‡å­¦ã€å­¦æœ¯ã€é€šç”¨
- âœ… **è´¨é‡è¯„ä¼°**: å‹ç¼©æ¯”ã€è¯æ±‡è¦†ç›–ç‡ã€é‡å¤åº¦
- âœ… **ä¸“å®¶åˆ†æ**: ä¸“å®¶ä½¿ç”¨åˆ†å¸ƒå’Œè´Ÿè½½å‡è¡¡
- âœ… **æ‰¹é‡å¤„ç†**: æ”¯æŒæ‰¹é‡æ–‡æœ¬æ‘˜è¦
- âœ… **å¯è§†åŒ–**: ç”Ÿæˆä¸“å®¶ä½¿ç”¨åˆ†æå›¾è¡¨

### 2. ä»£ç ç”ŸæˆåŠ©æ‰‹

#### æ ¸å¿ƒåŠŸèƒ½

```python
from course.code_examples.code_generation_assistant import CodeGenerationAssistant

# åˆå§‹åŒ–
assistant = CodeGenerationAssistant()

# ç”Ÿæˆä»£ç 
result = assistant.generate_code(
    prompt="è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—",
    language="python",  # å¯é€‰: python, javascript, java
    code_type="function"  # å¯é€‰: function, class, script, complete, comment
)

print(f"ç”Ÿæˆçš„ä»£ç :\n{result['code']}")
print(f"è´¨é‡è¯„åˆ†: {result['quality_metrics']['overall_score']}")
```

#### æ”¯æŒçš„åŠŸèƒ½

- âœ… **å¤šè¯­è¨€æ”¯æŒ**: Pythonã€JavaScriptã€Java
- âœ… **å¤šç§ç±»å‹**: å‡½æ•°ã€ç±»ã€è„šæœ¬ã€è¡¥å…¨ã€æ³¨é‡Š
- âœ… **è´¨é‡åˆ†æ**: ç¼©è¿›ã€å‘½åã€æ³¨é‡Šã€ç»“æ„è¯„åˆ†
- âœ… **ä¸“å®¶è·¯ç”±**: è¯­è¨€ç‰¹å®šçš„ä¸“å®¶åˆ†å¸ƒ
- âœ… **å¯è§†åŒ–**: ä»£ç åˆ†æå›¾è¡¨

### 3. MoEè·¯ç”±æœºåˆ¶æ¼”ç¤º

#### æ ¸å¿ƒåŠŸèƒ½

```python
from course.code_examples.moe_routing_demo import demonstrate_routing_strategies

# è¿è¡Œæ¼”ç¤º
demonstrate_routing_strategies()
```

#### æ”¯æŒçš„åŠŸèƒ½

- âœ… **å¤šç§è·¯ç”±å™¨**: ç®€å•ã€å™ªå£°ã€è´Ÿè½½å‡è¡¡
- âœ… **ä¸“å®¶ä¸“ä¸šåŒ–**: ä¸åŒè¾“å…¥ç‰¹å¾çš„ä¸“å®¶é€‰æ‹©
- âœ… **å®¹é‡åˆ†æ**: å®¹é‡é™åˆ¶å¯¹è·¯ç”±çš„å½±å“
- âœ… **å¯è§†åŒ–**: è·¯ç”±æ¨¡å¼çƒ­åŠ›å›¾å’Œè´Ÿè½½åˆ†å¸ƒ

---

## ğŸ” æ·±å…¥ç†è§£

### MoEæ¶æ„åŸç†

```python
# MoEå±‚çš„åŸºæœ¬ç»“æ„
class MoELayer:
    def __init__(self, num_experts, num_experts_per_tok):
        self.experts = [Expert() for _ in range(num_experts)]
        self.router = Router(num_experts)
        self.num_experts_per_tok = num_experts_per_tok
    
    def forward(self, x):
        # 1. è·¯ç”±å†³ç­–
        routing_weights, selected_experts = self.router(x)
        
        # 2. ä¸“å®¶å¤„ç†
        outputs = []
        for expert_id in selected_experts:
            expert_output = self.experts[expert_id](x)
            outputs.append(expert_output)
        
        # 3. åŠ æƒç»„åˆ
        return sum(w * out for w, out in zip(routing_weights, outputs))
```

### è·¯ç”±æœºåˆ¶

```python
# Top-Kè·¯ç”±ç®—æ³•
def top_k_routing(logits, k=2):
    # é€‰æ‹©top-kä¸“å®¶
    weights, selected = ops.topk(logits, k=k)
    
    # è®¡ç®—æƒé‡
    weights = ops.softmax(weights, axis=-1)
    
    return weights, selected
```

### è´¨é‡è¯„ä¼°

```python
# æ‘˜è¦è´¨é‡è¯„ä¼°
def evaluate_summary_quality(original_text, summary):
    # å‹ç¼©æ¯”
    compression_ratio = len(summary) / len(original_text)
    
    # è¯æ±‡è¦†ç›–ç‡
    original_words = set(original_text.lower().split())
    summary_words = set(summary.lower().split())
    vocabulary_coverage = len(original_words.intersection(summary_words)) / len(original_words)
    
    # ç»¼åˆè¯„åˆ†
    quality_score = (
        min(compression_ratio * 2, 1.0) * 0.3 +
        vocabulary_coverage * 0.4 +
        (1 - repetition_ratio) * 0.3
    )
    
    return quality_score
```

---

## ğŸ› ï¸ è‡ªå®šä¹‰é…ç½®

### è°ƒæ•´MoEå‚æ•°

```python
# è‡ªå®šä¹‰MoEé…ç½®
config = MistralConfig(
    vocab_size=32000,
    hidden_size=512,
    num_hidden_layers=6,
    moe=MoeConfig(
        num_experts=8,              # ä¸“å®¶æ•°é‡
        num_experts_per_tok=2,      # æ¯tokenä½¿ç”¨çš„ä¸“å®¶æ•°
        router_jitter_noise=0.01    # è·¯ç”±å™ªå£°
    )
)
```

### è‡ªå®šä¹‰è´¨é‡è¯„ä¼°

```python
# æ·»åŠ è‡ªå®šä¹‰è´¨é‡è¯„ä¼°è§„åˆ™
def custom_quality_check(code, language):
    # å®ç°è‡ªå®šä¹‰è´¨é‡æ£€æŸ¥é€»è¾‘
    score = 0.0
    
    # æ£€æŸ¥ä»£ç é•¿åº¦
    if len(code) > 100:
        score += 0.2
    
    # æ£€æŸ¥å‡½æ•°æ•°é‡
    function_count = code.count('def ')
    if function_count > 0:
        score += 0.3
    
    return min(score, 1.0)
```

### è‡ªå®šä¹‰å¯è§†åŒ–

```python
# è‡ªå®šä¹‰å¯è§†åŒ–æ ·å¼
def custom_visualization(data, title):
    plt.style.use('seaborn')
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # è‡ªå®šä¹‰å›¾è¡¨
    ax.plot(data)
    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.set_xlabel('Index', fontsize=12)
    ax.set_ylabel('Value', fontsize=12)
    
    plt.tight_layout()
    plt.savefig(f'{title}.png', dpi=150, bbox_inches='tight')
    plt.show()
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•è§£å†³å†…å­˜ä¸è¶³é—®é¢˜ï¼Ÿ

**A**: 
```python
# å‡å°‘æ‰¹æ¬¡å¤§å°
config.batch_size = 1

# ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model.gradient_checkpointing_enable()

# å¯ç”¨æ··åˆç²¾åº¦
from mindspore import amp
model = amp.auto_mixed_precision(model)
```

### Q2: å¦‚ä½•æé«˜ä»£ç ç”Ÿæˆè´¨é‡ï¼Ÿ

**A**:
```python
# ä¼˜åŒ–æç¤ºæ¨¡æ¿
prompt = f"""
è¯·ç”¨{language}ç¼–å†™ä¸€ä¸ªé«˜è´¨é‡çš„{code_type}ï¼Œè¦æ±‚ï¼š
1. ä»£ç ç»“æ„æ¸…æ™°
2. å‘½åè§„èŒƒ
3. åŒ…å«è¯¦ç»†æ³¨é‡Š
4. å®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š{user_prompt}
"""

# è°ƒæ•´ç”Ÿæˆå‚æ•°
result = assistant.generate_code(
    prompt=prompt,
    language=language,
    code_type=code_type,
    temperature=0.7,  # æ§åˆ¶åˆ›é€ æ€§
    max_length=500    # æ§åˆ¶é•¿åº¦
)
```

### Q3: å¦‚ä½•å¤„ç†ä¸­æ–‡æ–‡æœ¬ï¼Ÿ

**A**:
```python
# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ä½¿ç”¨ä¸­æ–‡åˆ†è¯å™¨
import jieba
def chinese_tokenize(text):
    return list(jieba.cut(text))
```

### Q4: å¦‚ä½•ä¼˜åŒ–æ¨ç†é€Ÿåº¦ï¼Ÿ

**A**:
```python
# å¯ç”¨ç¼“å­˜
model.config.use_cache = True

# æ‰¹é‡å¤„ç†
def batch_inference(inputs, batch_size=4):
    results = []
    for i in range(0, len(inputs), batch_size):
        batch = inputs[i:i+batch_size]
        outputs = model(batch)
        results.extend(outputs)
    return results

# æ¨¡å‹é‡åŒ–
from mindspore import quantization
quantized_model = quantization.quantize_dynamic(model)
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ¨¡å‹é…ç½®ä¼˜åŒ–

```python
# æ¨èçš„é…ç½®å‚æ•°
optimal_config = {
    'num_experts': 8,              # ä¸“å®¶æ•°é‡
    'num_experts_per_tok': 2,      # æ¯tokenä¸“å®¶æ•°
    'router_jitter_noise': 0.01,   # è·¯ç”±å™ªå£°
    'load_balancing_weight': 0.01, # è´Ÿè½½å‡è¡¡æƒé‡
    'capacity_factor': 1.5         # å®¹é‡å› å­
}
```

### 2. è®­ç»ƒç­–ç•¥ä¼˜åŒ–

```python
# è®­ç»ƒæ—¶çš„æœ€ä½³å®è·µ
def optimal_training_step(model, batch):
    # å‰å‘ä¼ æ’­
    outputs = model(batch['input_ids'], labels=batch['labels'])
    loss = outputs[0]
    
    # æ·»åŠ è´Ÿè½½å‡è¡¡æŸå¤±
    if hasattr(model, 'moe_layers'):
        load_balancing_loss = sum(
            layer.aux_loss for layer in model.moe_layers 
            if hasattr(layer, 'aux_loss')
        )
        loss += 0.01 * load_balancing_loss
    
    return loss
```

### 3. æ¨ç†ä¼˜åŒ–

```python
# æ¨ç†æ—¶çš„ä¼˜åŒ–ç­–ç•¥
def optimized_inference(model, inputs):
    # è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼
    model.set_train(False)
    
    # å¯ç”¨ç¼“å­˜
    model.config.use_cache = True
    
    # æ‰¹é‡å¤„ç†
    batch_size = 4
    results = []
    
    for i in range(0, len(inputs), batch_size):
        batch = inputs[i:i+batch_size]
        outputs = model(batch)
        results.extend(outputs)
    
    return results
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

### 1. æ·±å…¥å­¦ä¹ 

- é˜…è¯»å®Œæ•´çš„[è¯¦ç»†æ•™ç¨‹](README.md)
- ç†è§£[æŠ€æœ¯åŸç†](README.md#æŠ€æœ¯åŸç†)
- æŒæ¡[æœ€ä½³å®è·µ](README.md#æœ€ä½³å®è·µ)

### 2. å®è·µé¡¹ç›®

- å°è¯•ä¿®æ”¹é…ç½®å‚æ•°
- æ·»åŠ æ–°çš„ä¸“å®¶ç±»å‹
- å®ç°è‡ªå®šä¹‰è·¯ç”±ç®—æ³•
- é›†æˆå¤–éƒ¨å·¥å…·

### 3. æ‰©å±•å¼€å‘

- æ·»åŠ æ–°çš„ç¼–ç¨‹è¯­è¨€æ”¯æŒ
- å®ç°æ›´å¤æ‚çš„è´¨é‡è¯„ä¼°
- åˆ›å»ºWebç•Œé¢
- éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

---

## ğŸ“ è·å–å¸®åŠ©

- **æ–‡æ¡£**: æŸ¥çœ‹[å®Œæ•´æ•™ç¨‹](README.md)
- **é—®é¢˜**: æäº¤[Issue](https://github.com/your-repo/issues)
- **è®¨è®º**: å‚ä¸[Discussions](https://github.com/your-repo/discussions)

---

*å¿«é€Ÿå…¥é—¨æŒ‡å— v1.0.0*
*æœ€åæ›´æ–°: 2025-08-27*
