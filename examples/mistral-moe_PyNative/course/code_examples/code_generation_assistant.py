# Copyright 2025 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
ä»£ç ç”ŸæˆåŠ©æ‰‹ - åŸºäºMistral MoEæ¨¡å‹

æœ¬åº”ç”¨æ¡ˆä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨Mistral MoEæ¨¡å‹è¿›è¡Œæ™ºèƒ½ä»£ç ç”Ÿæˆï¼Œ
åŒ…æ‹¬ï¼š
1. å¤šè¯­è¨€ä»£ç ç”Ÿæˆï¼ˆPythonã€JavaScriptã€Javaç­‰ï¼‰
2. ä»£ç è¡¥å…¨å’Œä¿®å¤
3. ä»£ç æ³¨é‡Šç”Ÿæˆ
4. ä»£ç è´¨é‡åˆ†æ
5. ä¸“å®¶è·¯ç”±ä¼˜åŒ–
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import mindspore
from mindspore import nn, ops, context, Tensor
import numpy as np
import time
import json
import re
from typing import List, Dict, Tuple, Optional
import matplotlib.pyplot as plt

# å¯¼å…¥é¡¹ç›®æ¨¡å‹
from models.mistral.configuration_mistral import MistralConfig, MoeConfig
from models.mistral.modeling_mistral import MistralModel
from models.mistral.tokenization_mistral import MistralTokenizer

# è®¾ç½®åŠ¨æ€å›¾æ¨¡å¼
context.set_context(mode=context.PYNATIVE_MODE)


class CodeGenerationAssistant:
    """ä»£ç ç”ŸæˆåŠ©æ‰‹"""
    
    def __init__(self, model_path: str = None, max_length: int = 2048):
        """
        åˆå§‹åŒ–ä»£ç ç”ŸæˆåŠ©æ‰‹
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            max_length: æœ€å¤§åºåˆ—é•¿åº¦
        """
        self.max_length = max_length
        
        # åˆå§‹åŒ–é…ç½®
        if model_path and os.path.exists(model_path):
            self.config = MistralConfig.from_pretrained(model_path)
        else:
            # ä½¿ç”¨å°å‹é…ç½®ç”¨äºæ¼”ç¤º
            self.config = MistralConfig(
                vocab_size=32000,
                hidden_size=512,
                intermediate_size=1024,
                num_hidden_layers=6,
                num_attention_heads=8,
                num_key_value_heads=4,
                hidden_act="silu",
                max_position_embeddings=4096,
                initializer_range=0.02,
                rms_norm_eps=1e-6,
                use_cache=True,
                pad_token_id=None,
                bos_token_id=1,
                eos_token_id=2,
                tie_word_embeddings=False,
                rope_theta=10000.0,
                sliding_window=4096,
                attention_dropout=0.0,
                moe=MoeConfig(num_experts=4, num_experts_per_tok=2)  # MoEé…ç½®
            )
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = MistralModel(self.config)
        
        # åˆå§‹åŒ–åˆ†è¯å™¨
        self.tokenizer = self._create_code_tokenizer()
        
        # ä»£ç ç”Ÿæˆæç¤ºæ¨¡æ¿
        self.code_prompts = {
            "python": {
                "function": "è¯·ç”¨Pythonç¼–å†™ä¸€ä¸ªå‡½æ•°ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š\n\n",
                "class": "è¯·ç”¨Pythonç¼–å†™ä¸€ä¸ªç±»ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š\n\n",
                "script": "è¯·ç”¨Pythonç¼–å†™ä¸€ä¸ªè„šæœ¬ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š\n\n",
                "complete": "è¯·è¡¥å…¨ä»¥ä¸‹Pythonä»£ç ï¼š\n\n",
                "comment": "è¯·ä¸ºä»¥ä¸‹Pythonä»£ç æ·»åŠ è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼š\n\n"
            },
            "javascript": {
                "function": "è¯·ç”¨JavaScriptç¼–å†™ä¸€ä¸ªå‡½æ•°ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š\n\n",
                "class": "è¯·ç”¨JavaScriptç¼–å†™ä¸€ä¸ªç±»ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š\n\n",
                "script": "è¯·ç”¨JavaScriptç¼–å†™ä¸€ä¸ªè„šæœ¬ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š\n\n",
                "complete": "è¯·è¡¥å…¨ä»¥ä¸‹JavaScriptä»£ç ï¼š\n\n",
                "comment": "è¯·ä¸ºä»¥ä¸‹JavaScriptä»£ç æ·»åŠ è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼š\n\n"
            },
            "java": {
                "function": "è¯·ç”¨Javaç¼–å†™ä¸€ä¸ªæ–¹æ³•ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š\n\n",
                "class": "è¯·ç”¨Javaç¼–å†™ä¸€ä¸ªç±»ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š\n\n",
                "script": "è¯·ç”¨Javaç¼–å†™ä¸€ä¸ªç¨‹åºï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š\n\n",
                "complete": "è¯·è¡¥å…¨ä»¥ä¸‹Javaä»£ç ï¼š\n\n",
                "comment": "è¯·ä¸ºä»¥ä¸‹Javaä»£ç æ·»åŠ è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼š\n\n"
            }
        }
        
        # ä»£ç è´¨é‡æ£€æŸ¥è§„åˆ™
        self.code_quality_rules = {
            "python": {
                "indentation": r"^(\s{4})+",  # 4ç©ºæ ¼ç¼©è¿›
                "naming": r"^[a-z_][a-z0-9_]*$",  # å°å†™ä¸‹åˆ’çº¿å‘½å
                "docstring": r'""".*"""',  # æ–‡æ¡£å­—ç¬¦ä¸²
                "imports": r"^import\s+|^from\s+",  # å¯¼å…¥è¯­å¥
            },
            "javascript": {
                "indentation": r"^(\s{2})+",  # 2ç©ºæ ¼ç¼©è¿›
                "naming": r"^[a-z][a-zA-Z0-9]*$",  # é©¼å³°å‘½å
                "comments": r"//.*|/\*.*\*/",  # æ³¨é‡Š
                "imports": r"^import\s+|^const\s+|^let\s+|^var\s+",  # å¯¼å…¥å’Œå£°æ˜
            },
            "java": {
                "indentation": r"^(\s{4})+",  # 4ç©ºæ ¼ç¼©è¿›
                "naming": r"^[A-Z][a-zA-Z0-9]*$",  # é©¼å³°å‘½å
                "comments": r"//.*|/\*.*\*/",  # æ³¨é‡Š
                "imports": r"^import\s+|^public\s+class\s+",  # å¯¼å…¥å’Œç±»å£°æ˜
            }
        }
        
        print(f"âœ… ä»£ç ç”ŸæˆåŠ©æ‰‹åˆå§‹åŒ–å®Œæˆ")
        print(f"   - æ¨¡å‹é…ç½®: {self.config.hidden_size}ç»´, {self.config.num_hidden_layers}å±‚")
        print(f"   - MoEä¸“å®¶: {self.config.moe.num_experts}ä¸ªä¸“å®¶, æ¯tokenä½¿ç”¨{self.config.moe.num_experts_per_tok}ä¸ª")
        print(f"   - æ”¯æŒè¯­è¨€: Python, JavaScript, Java")
        print(f"   - æœ€å¤§é•¿åº¦: {self.max_length}")
    
    def _create_code_tokenizer(self):
        """åˆ›å»ºä»£ç ä¸“ç”¨åˆ†è¯å™¨"""
        class CodeTokenizer:
            def __init__(self):
                self.vocab_size = 32000
                self.pad_token_id = 0
                self.bos_token_id = 1
                self.eos_token_id = 2
                self.unk_token_id = 3
                
                # åˆ›å»ºä»£ç è¯æ±‡è¡¨
                self.char_to_id = {chr(i): i + 4 for i in range(32, 127)}  # å¯æ‰“å°ASCIIå­—ç¬¦
                self.char_to_id.update({
                    '<pad>': 0, '<bos>': 1, '<eos>': 2, '<unk>': 3,
                    '\n': 10, '\t': 9, ' ': 32  # ç‰¹æ®Šå­—ç¬¦
                })
                self.id_to_char = {v: k for k, v in self.char_to_id.items()}
            
            def encode(self, text: str, max_length: int = None) -> List[int]:
                """ç¼–ç æ–‡æœ¬ä¸ºtoken ID"""
                tokens = [self.bos_token_id]
                
                for char in text:
                    if char in self.char_to_id:
                        tokens.append(self.char_to_id[char])
                    else:
                        tokens.append(self.unk_token_id)
                
                tokens.append(self.eos_token_id)
                
                if max_length:
                    tokens = tokens[:max_length]
                    if len(tokens) < max_length:
                        tokens.extend([self.pad_token_id] * (max_length - len(tokens)))
                
                return tokens
            
            def decode(self, token_ids: List[int]) -> str:
                """è§£ç token IDä¸ºæ–‡æœ¬"""
                text = ""
                for token_id in token_ids:
                    if token_id in self.id_to_char:
                        char = self.id_to_char[token_id]
                        if char not in ['<pad>', '<bos>', '<eos>', '<unk>']:
                            text += char
                return text
        
        return CodeTokenizer()
    
    def _analyze_code_expert_usage(self, input_ids: Tensor, language: str) -> Dict:
        """åˆ†æä»£ç ç”Ÿæˆä¸­çš„ä¸“å®¶ä½¿ç”¨æƒ…å†µ"""
        try:
            # æ ¹æ®ç¼–ç¨‹è¯­è¨€è°ƒæ•´ä¸“å®¶åˆ†å¸ƒï¼ˆæ¨¡æ‹Ÿï¼‰
            if language == "python":
                # Pythonä»£ç å¯èƒ½æ›´å€¾å‘äºä½¿ç”¨æŸäº›ä¸“å®¶
                expert_dist = np.array([0.3, 0.25, 0.25, 0.2])
            elif language == "javascript":
                # JavaScriptä»£ç çš„ä¸“å®¶åˆ†å¸ƒ
                expert_dist = np.array([0.25, 0.3, 0.2, 0.25])
            elif language == "java":
                # Javaä»£ç çš„ä¸“å®¶åˆ†å¸ƒ
                expert_dist = np.array([0.2, 0.25, 0.3, 0.25])
            else:
                expert_dist = np.random.dirichlet(np.ones(self.config.moe.num_experts))
            
            expert_usage = {
                'total_tokens': input_ids.shape[1],
                'language': language,
                'expert_distribution': expert_dist.tolist(),
                'load_balance_score': np.random.uniform(0.75, 0.95),
                'specialization_score': np.random.uniform(0.7, 0.9),
                'code_complexity': self._analyze_code_complexity(input_ids)
            }
            
            return expert_usage
            
        except Exception as e:
            print(f"âš ï¸ ä»£ç ä¸“å®¶ä½¿ç”¨åˆ†æå‡ºé”™: {e}")
            return {
                'total_tokens': input_ids.shape[1],
                'language': language,
                'expert_distribution': [0.25] * self.config.moe.num_experts,
                'load_balance_score': 0.8,
                'specialization_score': 0.7,
                'code_complexity': 'medium'
            }
    
    def _analyze_code_complexity(self, input_ids: Tensor) -> str:
        """åˆ†æä»£ç å¤æ‚åº¦"""
        try:
            # å°†token IDè½¬æ¢å›æ–‡æœ¬
            text = self.tokenizer.decode(input_ids[0].asnumpy().tolist())
            
            # ç®€å•çš„å¤æ‚åº¦åˆ†æ
            lines = text.split('\n')
            avg_line_length = np.mean([len(line) for line in lines if line.strip()])
            
            if avg_line_length > 80:
                return 'high'
            elif avg_line_length > 50:
                return 'medium'
            else:
                return 'low'
                
        except Exception:
            return 'medium'
    
    def _evaluate_code_quality(self, code: str, language: str) -> Dict:
        """è¯„ä¼°ä»£ç è´¨é‡"""
        quality_metrics = {
            'language': language,
            'total_lines': len(code.split('\n')),
            'code_length': len(code),
            'indentation_score': 0.0,
            'naming_score': 0.0,
            'comment_score': 0.0,
            'structure_score': 0.0,
            'overall_score': 0.0
        }
        
        try:
            lines = code.split('\n')
            rules = self.code_quality_rules.get(language, {})
            
            # æ£€æŸ¥ç¼©è¿›
            indentation_matches = 0
            for line in lines:
                if line.strip() and re.match(rules.get('indentation', r'^\s*'), line):
                    indentation_matches += 1
            quality_metrics['indentation_score'] = indentation_matches / len(lines) if lines else 0
            
            # æ£€æŸ¥å‘½åè§„èŒƒ
            naming_matches = 0
            words = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', code)
            for word in words:
                if re.match(rules.get('naming', r'^[a-zA-Z_][a-zA-Z0-9_]*$'), word):
                    naming_matches += 1
            quality_metrics['naming_score'] = naming_matches / len(words) if words else 0
            
            # æ£€æŸ¥æ³¨é‡Š
            comment_lines = len(re.findall(rules.get('comments', r'//.*|/\*.*\*/'), code))
            quality_metrics['comment_score'] = min(comment_lines / len(lines), 1.0) if lines else 0
            
            # æ£€æŸ¥ç»“æ„
            structure_score = 0
            if language == "python":
                if 'def ' in code or 'class ' in code:
                    structure_score += 0.5
                if 'import ' in code or 'from ' in code:
                    structure_score += 0.3
                if '"""' in code or "'''" in code:
                    structure_score += 0.2
            elif language == "javascript":
                if 'function ' in code or '=>' in code:
                    structure_score += 0.5
                if 'import ' in code or 'const ' in code or 'let ' in code:
                    structure_score += 0.3
                if '//' in code or '/*' in code:
                    structure_score += 0.2
            elif language == "java":
                if 'public ' in code or 'private ' in code:
                    structure_score += 0.5
                if 'import ' in code:
                    structure_score += 0.3
                if '//' in code or '/*' in code:
                    structure_score += 0.2
            
            quality_metrics['structure_score'] = structure_score
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            quality_metrics['overall_score'] = (
                quality_metrics['indentation_score'] * 0.2 +
                quality_metrics['naming_score'] * 0.3 +
                quality_metrics['comment_score'] * 0.2 +
                quality_metrics['structure_score'] * 0.3
            )
            
        except Exception as e:
            print(f"âš ï¸ ä»£ç è´¨é‡è¯„ä¼°å‡ºé”™: {e}")
        
        return quality_metrics
    
    def generate_code(self, 
                     prompt: str, 
                     language: str = "python",
                     code_type: str = "function",
                     max_length: int = 500,
                     temperature: float = 0.7) -> Dict:
        """
        ç”Ÿæˆä»£ç 
        
        Args:
            prompt: ä»£ç ç”Ÿæˆæç¤º
            language: ç¼–ç¨‹è¯­è¨€ (python, javascript, java)
            code_type: ä»£ç ç±»å‹ (function, class, script, complete, comment)
            max_length: æœ€å¤§ä»£ç é•¿åº¦
            temperature: ç”Ÿæˆæ¸©åº¦
            
        Returns:
            åŒ…å«ä»£ç å’Œå…ƒä¿¡æ¯çš„å­—å…¸
        """
        start_time = time.time()
        
        try:
            # æ„å»ºæç¤º
            if language in self.code_prompts and code_type in self.code_prompts[language]:
                template = self.code_prompts[language][code_type]
            else:
                template = f"è¯·ç”¨{language}ç¼–å†™ä»£ç ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š\n\n"
            
            full_prompt = template + prompt
            
            # ç¼–ç è¾“å…¥
            input_ids = self.tokenizer.encode(full_prompt, max_length=self.max_length)
            input_tensor = Tensor([input_ids], mindspore.int32)
            
            # åˆ†æä¸“å®¶ä½¿ç”¨æƒ…å†µ
            expert_analysis = self._analyze_code_expert_usage(input_tensor, language)
            
            # ç”Ÿæˆä»£ç ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…éœ€è¦å®Œæ•´çš„è‡ªå›å½’ç”Ÿæˆï¼‰
            generated_code = self._simulate_code_generation(prompt, language, code_type, max_length, temperature)
            
            # è¯„ä¼°ä»£ç è´¨é‡
            quality_metrics = self._evaluate_code_quality(generated_code, language)
            
            # è®¡ç®—ç”Ÿæˆæ—¶é—´
            generation_time = time.time() - start_time
            
            return {
                'code': generated_code,
                'prompt': prompt,
                'language': language,
                'code_type': code_type,
                'expert_analysis': expert_analysis,
                'quality_metrics': quality_metrics,
                'generation_time': generation_time,
                'input_tokens': len(input_ids),
                'output_tokens': len(generated_code.split())
            }
            
        except Exception as e:
            print(f"âŒ ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            return {
                'code': f"# ä»£ç ç”Ÿæˆå¤±è´¥: {str(e)}",
                'prompt': prompt,
                'language': language,
                'code_type': code_type,
                'expert_analysis': {},
                'quality_metrics': {},
                'generation_time': time.time() - start_time,
                'input_tokens': 0,
                'output_tokens': 0
            }
    
    def _simulate_code_generation(self, prompt: str, language: str, code_type: str, max_length: int, temperature: float) -> str:
        """æ¨¡æ‹Ÿä»£ç ç”Ÿæˆï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        
        # æ ¹æ®è¯­è¨€å’Œç±»å‹ç”Ÿæˆç¤ºä¾‹ä»£ç 
        if language == "python":
            if code_type == "function":
                return f'''def {prompt.lower().replace(" ", "_")}():
    """
    {prompt}
    """
    # TODO: å®ç°å…·ä½“åŠŸèƒ½
    pass'''
            
            elif code_type == "class":
                return f'''class {prompt.replace(" ", "")}:
    """
    {prompt}
    """
    
    def __init__(self):
        # åˆå§‹åŒ–ä»£ç 
        pass
    
    def process(self):
        # å¤„ç†é€»è¾‘
        pass'''
            
            elif code_type == "script":
                return f'''#!/usr/bin/env python3
"""
{prompt}
"""

import sys

def main():
    # ä¸»å‡½æ•°é€»è¾‘
    print("Hello, World!")
    
if __name__ == "__main__":
    main()'''
            
            elif code_type == "complete":
                return f'''# è¡¥å…¨ä»£ç 
{prompt}
    # å®ç°å…·ä½“é€»è¾‘
    pass'''
            
            elif code_type == "comment":
                return f'''# {prompt}
# è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹ä»£ç ï¼Œç”¨äºæ¼”ç¤ºæ³¨é‡ŠåŠŸèƒ½
# å¯ä»¥æ ¹æ®å®é™…éœ€è¦æ·»åŠ æ›´å¤šæ³¨é‡Š'''
        
        elif language == "javascript":
            if code_type == "function":
                return f'''function {prompt.lower().replace(" ", "_")}() {{
    // {prompt}
    // TODO: å®ç°å…·ä½“åŠŸèƒ½
    return null;
}}'''
            
            elif code_type == "class":
                return f'''class {prompt.replace(" ", "")} {{
    constructor() {{
        // åˆå§‹åŒ–ä»£ç 
    }}
    
    process() {{
        // å¤„ç†é€»è¾‘
    }}
}}'''
            
            elif code_type == "complete":
                return f'''// è¡¥å…¨ä»£ç 
{prompt}
    // å®ç°å…·ä½“é€»è¾‘
    return null;'''
            
            elif code_type == "comment":
                return f'''// {prompt}
// è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹ä»£ç ï¼Œç”¨äºæ¼”ç¤ºæ³¨é‡ŠåŠŸèƒ½
// å¯ä»¥æ ¹æ®å®é™…éœ€è¦æ·»åŠ æ›´å¤šæ³¨é‡Š'''
        
        elif language == "java":
            if code_type == "function":
                return f'''public void {prompt.lower().replace(" ", "_")}() {{
    // {prompt}
    // TODO: å®ç°å…·ä½“åŠŸèƒ½
}}'''
            
            elif code_type == "class":
                return f'''public class {prompt.replace(" ", "")} {{
    // {prompt}
    
    public {prompt.replace(" ", "")}() {{
        // æ„é€ å‡½æ•°
    }}
    
    public void process() {{
        // å¤„ç†é€»è¾‘
    }}
}}'''
            
            elif code_type == "complete":
                return f'''// è¡¥å…¨ä»£ç 
{prompt}
    // å®ç°å…·ä½“é€»è¾‘
}}'''
            
            elif code_type == "comment":
                return f'''// {prompt}
// è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹ä»£ç ï¼Œç”¨äºæ¼”ç¤ºæ³¨é‡ŠåŠŸèƒ½
// å¯ä»¥æ ¹æ®å®é™…éœ€è¦æ·»åŠ æ›´å¤šæ³¨é‡Š'''
        
        # é»˜è®¤è¿”å›
        return f"// {prompt}\n// ä»£ç ç”Ÿæˆä¸­..."
    
    def complete_code(self, partial_code: str, language: str = "python") -> Dict:
        """ä»£ç è¡¥å…¨"""
        return self.generate_code(partial_code, language, "complete")
    
    def add_comments(self, code: str, language: str = "python") -> Dict:
        """æ·»åŠ ä»£ç æ³¨é‡Š"""
        return self.generate_code(code, language, "comment")
    
    def batch_generate(self, prompts: List[Tuple[str, str, str]]) -> List[Dict]:
        """æ‰¹é‡ç”Ÿæˆä»£ç """
        results = []
        
        print(f"ğŸ”„ å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(prompts)} ä¸ªä»£ç ...")
        
        for i, (prompt, language, code_type) in enumerate(prompts):
            print(f"  ç”Ÿæˆç¬¬ {i+1}/{len(prompts)} ä¸ªä»£ç ...")
            result = self.generate_code(prompt, language, code_type)
            results.append(result)
        
        print(f"âœ… æ‰¹é‡ç”Ÿæˆå®Œæˆ")
        return results
    
    def visualize_code_analysis(self, results: List[Dict], save_path: str = None):
        """å¯è§†åŒ–ä»£ç åˆ†æç»“æœ"""
        try:
            # è®¾ç½®ä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
            
            # è¯­è¨€åˆ†å¸ƒ
            languages = [r['language'] for r in results]
            language_counts = {}
            for lang in languages:
                language_counts[lang] = language_counts.get(lang, 0) + 1
            
            ax1.pie(language_counts.values(), labels=language_counts.keys(), autopct='%1.1f%%')
            ax1.set_title('Programming Language Distribution')
            
            # ä»£ç è´¨é‡è¯„åˆ†
            quality_scores = [r['quality_metrics'].get('overall_score', 0) for r in results]
            ax2.hist(quality_scores, bins=10, alpha=0.7, edgecolor='black')
            ax2.set_xlabel('Code Quality Score')
            ax2.set_ylabel('Number of Codes')
            ax2.set_title('Code Quality Distribution')
            ax2.axvline(np.mean(quality_scores), color='red', linestyle='--', label=f'Average: {np.mean(quality_scores):.2f}')
            ax2.legend()
            
            # ä¸“å®¶ä½¿ç”¨çƒ­åŠ›å›¾
            expert_data = []
            for r in results:
                expert_dist = r['expert_analysis'].get('expert_distribution', [0.25] * 4)
                expert_data.append(expert_dist)
            
            if expert_data:
                expert_matrix = np.array(expert_data)
                im = ax3.imshow(expert_matrix.T, cmap='YlOrRd', aspect='auto')
                ax3.set_xlabel('Code Samples')
                ax3.set_ylabel('Expert ID')
                ax3.set_title('Expert Usage Heatmap')
                plt.colorbar(im, ax=ax3)
            
            # æ€§èƒ½æŒ‡æ ‡
            generation_times = [r['generation_time'] for r in results]
            code_lengths = [r['quality_metrics'].get('code_length', 0) for r in results]
            
            ax4.scatter(code_lengths, generation_times, alpha=0.6)
            ax4.set_xlabel('Code Length')
            ax4.set_ylabel('Generation Time (s)')
            ax4.set_title('Code Length vs Generation Time')
            
            # æ·»åŠ è¶‹åŠ¿çº¿
            if len(code_lengths) > 1:
                z = np.polyfit(code_lengths, generation_times, 1)
                p = np.poly1d(z)
                ax4.plot(code_lengths, p(code_lengths), "r--", alpha=0.8)
            
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=150, bbox_inches='tight')
                print(f"ğŸ“Š ä»£ç åˆ†æå›¾å·²ä¿å­˜: {save_path}")
            
            plt.show()
            
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def generate_code_report(self, results: List[Dict], output_path: str = "code_generation_report.json"):
        """ç”Ÿæˆä»£ç ç”ŸæˆæŠ¥å‘Š"""
        try:
            # ç»Ÿè®¡ä¿¡æ¯
            languages = [r['language'] for r in results]
            language_stats = {}
            for lang in set(languages):
                language_stats[lang] = languages.count(lang)
            
            quality_scores = [r['quality_metrics'].get('overall_score', 0) for r in results]
            generation_times = [r['generation_time'] for r in results]
            
            report = {
                'summary': {
                    'total_codes': len(results),
                    'language_distribution': language_stats,
                    'average_quality_score': np.mean(quality_scores),
                    'average_generation_time': np.mean(generation_times),
                    'total_input_tokens': sum([r['input_tokens'] for r in results]),
                    'total_output_tokens': sum([r['output_tokens'] for r in results])
                },
                'quality_analysis': {
                    'best_quality': max(quality_scores),
                    'worst_quality': min(quality_scores),
                    'quality_std': np.std(quality_scores),
                    'high_quality_codes': len([s for s in quality_scores if s > 0.8])
                },
                'performance_analysis': {
                    'fastest_generation': min(generation_times),
                    'slowest_generation': max(generation_times),
                    'generation_time_std': np.std(generation_times)
                },
                'results': results
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ ä»£ç ç”ŸæˆæŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            return report
            
        except Exception as e:
            print(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return None


def demo_code_generation_assistant():
    """æ¼”ç¤ºä»£ç ç”ŸæˆåŠ©æ‰‹"""
    print("="*80)
    print("ğŸ’» ä»£ç ç”ŸæˆåŠ©æ‰‹æ¼”ç¤º")
    print("="*80)
    
    # åˆå§‹åŒ–ä»£ç ç”ŸæˆåŠ©æ‰‹
    assistant = CodeGenerationAssistant()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        ("è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—", "python", "function"),
        ("å®ç°å¿«é€Ÿæ’åºç®—æ³•", "python", "function"),
        ("åˆ›å»ºä¸€ä¸ªå­¦ç”Ÿç®¡ç†ç±»", "python", "class"),
        ("å®ç°æ•°ç»„å»é‡åŠŸèƒ½", "javascript", "function"),
        ("åˆ›å»ºä¸€ä¸ªè´­ç‰©è½¦ç»„ä»¶", "javascript", "class"),
        ("å®ç°å­—ç¬¦ä¸²åè½¬", "java", "function"),
        ("åˆ›å»ºä¸€ä¸ªå›¾ä¹¦ç®¡ç†ç³»ç»Ÿ", "java", "class"),
    ]
    
    # ç”Ÿæˆä»£ç 
    results = []
    for prompt, language, code_type in test_cases:
        print(f"\nğŸ’» ç”Ÿæˆ {language} {code_type}: {prompt}")
        result = assistant.generate_code(prompt, language, code_type)
        results.append(result)
        
        # æ‰“å°ç»“æœ
        print(f"   è¯­è¨€: {result['language']}")
        print(f"   ç±»å‹: {result['code_type']}")
        print(f"   ç”Ÿæˆæ—¶é—´: {result['generation_time']:.3f} ç§’")
        print(f"   è´¨é‡è¯„åˆ†: {result['quality_metrics'].get('overall_score', 0):.3f}")
        print(f"   ä»£ç é•¿åº¦: {result['quality_metrics'].get('code_length', 0)} å­—ç¬¦")
        print(f"   ä»£ç é¢„è§ˆ: {result['code'][:100]}...")
    
    # ä»£ç è¡¥å…¨ç¤ºä¾‹
    print(f"\nğŸ”§ ä»£ç è¡¥å…¨ç¤ºä¾‹:")
    partial_code = "def calculate_area(radius):\n    # è®¡ç®—åœ†çš„é¢ç§¯\n    "
    completion_result = assistant.complete_code(partial_code, "python")
    print(f"   è¡¥å…¨ç»“æœ: {completion_result['code']}")
    
    # æ·»åŠ æ³¨é‡Šç¤ºä¾‹
    print(f"\nğŸ“ æ·»åŠ æ³¨é‡Šç¤ºä¾‹:")
    code_without_comments = "def factorial(n):\n    if n <= 1:\n        return 1\n    return n * factorial(n-1)"
    comment_result = assistant.add_comments(code_without_comments, "python")
    print(f"   æ³¨é‡Šç»“æœ: {comment_result['code']}")
    
    # å¯è§†åŒ–åˆ†æ
    print(f"\nğŸ“Š ç”Ÿæˆä»£ç åˆ†æå›¾...")
    assistant.visualize_code_analysis(results, "code_analysis.png")
    
    # ç”ŸæˆæŠ¥å‘Š
    print(f"\nğŸ“„ ç”Ÿæˆä»£ç æŠ¥å‘Š...")
    report = assistant.generate_code_report(results, "code_generation_report.json")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    if report:
        stats = report['summary']
        quality = report['quality_analysis']
        performance = report['performance_analysis']
        
        print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»ä»£ç æ•°: {stats['total_codes']}")
        print(f"   è¯­è¨€åˆ†å¸ƒ: {stats['language_distribution']}")
        print(f"   å¹³å‡è´¨é‡è¯„åˆ†: {stats['average_quality_score']:.3f}")
        print(f"   å¹³å‡ç”Ÿæˆæ—¶é—´: {stats['average_generation_time']:.3f} ç§’")
        print(f"   é«˜è´¨é‡ä»£ç æ•°: {quality['high_quality_codes']}")
        print(f"   æœ€å¿«ç”Ÿæˆæ—¶é—´: {performance['fastest_generation']:.3f} ç§’")
        print(f"   æœ€æ…¢ç”Ÿæˆæ—¶é—´: {performance['slowest_generation']:.3f} ç§’")
    
    print(f"\nâœ… ä»£ç ç”ŸæˆåŠ©æ‰‹æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    demo_code_generation_assistant()
