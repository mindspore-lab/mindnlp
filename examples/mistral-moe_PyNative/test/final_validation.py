# -*- coding: utf-8 -*-
"""
æœ€ç»ˆéªŒè¯è„šæœ¬ - éªŒè¯æ‰€æœ‰ä¿®å¤åçš„åŠŸèƒ½
"""

import time
import json
import mindspore
from mindspore import context, ops
import traceback

# è®¾ç½®åŠ¨æ€å›¾æ¨¡å¼
context.set_context(mode=context.PYNATIVE_MODE)

from models.mistral.configuration_mistral import MistralConfig, MoeConfig
from models.mistral.modeling_mistral import MistralForCausalLM, MistralMoELayer

class FinalValidator:
    def __init__(self):
        self.results = {}
        
    def test_basic_functionality(self):
        """æµ‹è¯•åŸºç¡€åŠŸèƒ½"""
        print("æµ‹è¯•1: åŸºç¡€æ¨¡å‹åŠŸèƒ½")
        print("-" * 40)
        
        try:
            # æ ‡å‡†æ¨¡å‹
            config = MistralConfig(
                vocab_size=100,
                hidden_size=64,
                num_hidden_layers=2,
                num_attention_heads=4,
                num_key_value_heads=2,
                head_dim=16,
                intermediate_size=128
            )
            
            model = MistralForCausalLM(config)
            input_ids = ops.randint(0, config.vocab_size, (2, 8))
            
            # å‰å‘ä¼ æ’­
            outputs = model(input_ids)
            
            # æ£€æŸ¥è¾“å‡º
            if isinstance(outputs, (list, tuple)):
                logits = outputs[1] if len(outputs) > 1 else outputs[0]
            else:
                logits = outputs
                
            expected_shape = (2, 8, config.vocab_size)
            assert logits.shape == expected_shape, f"å½¢çŠ¶é”™è¯¯: {logits.shape} != {expected_shape}"
            
            # æ•°å€¼æ£€æŸ¥
            assert not ops.isnan(logits).any(), "è¾“å‡ºåŒ…å«NaN"
            assert not ops.isinf(logits).any(), "è¾“å‡ºåŒ…å«Inf"
            
            print(f"âœ“ æ ‡å‡†æ¨¡å‹æµ‹è¯•é€šè¿‡ - è¾“å‡ºå½¢çŠ¶: {logits.shape}")
            self.results["åŸºç¡€åŠŸèƒ½"] = {"çŠ¶æ€": "é€šè¿‡", "å½¢çŠ¶": list(logits.shape)}
            return True
            
        except Exception as e:
            print(f"âœ— åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            self.results["åŸºç¡€åŠŸèƒ½"] = {"çŠ¶æ€": "å¤±è´¥", "é”™è¯¯": str(e)}
            return False
    
    def test_moe_functionality(self):
        """æµ‹è¯•MoEåŠŸèƒ½"""
        print("\næµ‹è¯•2: MoEæ¨¡å‹åŠŸèƒ½")
        print("-" * 40)
        
        try:
            # MoEæ¨¡å‹
            config = MistralConfig(
                vocab_size=50,
                hidden_size=32,
                num_hidden_layers=2,
                num_attention_heads=2,
                num_key_value_heads=1,
                head_dim=16,
                intermediate_size=64,
                moe=MoeConfig(num_experts=4, num_experts_per_tok=2)
            )
            
            model = MistralForCausalLM(config)
            input_ids = ops.randint(0, config.vocab_size, (1, 10))
            
            # å‰å‘ä¼ æ’­
            outputs = model(input_ids)
            
            if isinstance(outputs, (list, tuple)):
                logits = outputs[1] if len(outputs) > 1 else outputs[0]
            else:
                logits = outputs
                
            expected_shape = (1, 10, config.vocab_size)
            assert logits.shape == expected_shape, f"å½¢çŠ¶é”™è¯¯: {logits.shape} != {expected_shape}"
            
            # æ•°å€¼æ£€æŸ¥
            assert not ops.isnan(logits).any(), "è¾“å‡ºåŒ…å«NaN"
            assert not ops.isinf(logits).any(), "è¾“å‡ºåŒ…å«Inf"
            
            print(f"âœ“ MoEæ¨¡å‹æµ‹è¯•é€šè¿‡ - è¾“å‡ºå½¢çŠ¶: {logits.shape}")
            self.results["MoEåŠŸèƒ½"] = {"çŠ¶æ€": "é€šè¿‡", "å½¢çŠ¶": list(logits.shape)}
            return True
            
        except Exception as e:
            print(f"âœ— MoEåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            self.results["MoEåŠŸèƒ½"] = {"çŠ¶æ€": "å¤±è´¥", "é”™è¯¯": str(e)}
            return False
    
    def test_moe_routing(self):
        """æµ‹è¯•MoEè·¯ç”±æœºåˆ¶"""
        print("\næµ‹è¯•3: MoEè·¯ç”±æœºåˆ¶")
        print("-" * 40)
        
        try:
            config = MistralConfig(
                hidden_size=32,
                intermediate_size=64,
                moe=MoeConfig(num_experts=4, num_experts_per_tok=2)
            )
            
            moe_layer = MistralMoELayer(config)
            input_tensor = ops.randn(2, 8, config.hidden_size)
            
            # è·¯ç”±æµ‹è¯•
            output = moe_layer(input_tensor)
            
            assert output.shape == input_tensor.shape, f"å½¢çŠ¶é”™è¯¯: {output.shape} != {input_tensor.shape}"
            assert not ops.isnan(output).any(), "è¾“å‡ºåŒ…å«NaN"
            assert not ops.isinf(output).any(), "è¾“å‡ºåŒ…å«Inf"
            
            # æµ‹è¯•è·¯ç”±åˆ†å¸ƒ
            hidden_flat = input_tensor.reshape(-1, config.hidden_size)
            router_logits = moe_layer.gate(hidden_flat)
            _, selected_experts = ops.topk(router_logits, config.moe.num_experts_per_tok)
            
            # æ£€æŸ¥ä¸“å®¶é€‰æ‹©
            assert (selected_experts >= 0).all(), "ä¸“å®¶ç´¢å¼•åŒ…å«è´Ÿæ•°"
            assert (selected_experts < config.moe.num_experts).all(), "ä¸“å®¶ç´¢å¼•è¶…å‡ºèŒƒå›´"
            
            print(f"âœ“ MoEè·¯ç”±æµ‹è¯•é€šè¿‡ - è¾“å‡ºå½¢çŠ¶: {output.shape}")
            self.results["MoEè·¯ç”±"] = {"çŠ¶æ€": "é€šè¿‡", "ä¸“å®¶æ•°": config.moe.num_experts}
            return True
            
        except Exception as e:
            print(f"âœ— MoEè·¯ç”±æµ‹è¯•å¤±è´¥: {e}")
            self.results["MoEè·¯ç”±"] = {"çŠ¶æ€": "å¤±è´¥", "é”™è¯¯": str(e)}
            return False
    
    def test_generation(self):
        """æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ"""
        print("\næµ‹è¯•4: æ–‡æœ¬ç”ŸæˆåŠŸèƒ½")
        print("-" * 40)
        
        try:
            config = MistralConfig(
                vocab_size=20,
                hidden_size=16,
                num_hidden_layers=1,
                num_attention_heads=2,
                num_key_value_heads=1,
                head_dim=8,
                intermediate_size=32,
                moe=MoeConfig(num_experts=2, num_experts_per_tok=1)
            )
            
            model = MistralForCausalLM(config)
            model.set_train(False)
            
            # ç”Ÿæˆæµ‹è¯•
            prompt = ops.randint(1, config.vocab_size-1, (1, 3))
            generated = prompt
            
            for i in range(5):
                outputs = model(generated)
                if isinstance(outputs, (list, tuple)):
                    logits = outputs[1] if len(outputs) > 1 else outputs[0]
                else:
                    logits = outputs
                    
                next_token = ops.argmax(logits[:, -1, :], dim=-1).unsqueeze(0)
                generated = ops.concat([generated, next_token], axis=1)
            
            assert generated.shape[1] == 8, f"ç”Ÿæˆé•¿åº¦é”™è¯¯: {generated.shape[1]} != 8"
            
            print(f"âœ“ æ–‡æœ¬ç”Ÿæˆæµ‹è¯•é€šè¿‡ - æœ€ç»ˆé•¿åº¦: {generated.shape[1]}")
            print(f"  ç”Ÿæˆåºåˆ—: {generated.asnumpy().flatten()}")
            self.results["æ–‡æœ¬ç”Ÿæˆ"] = {"çŠ¶æ€": "é€šè¿‡", "é•¿åº¦": generated.shape[1]}
            return True
            
        except Exception as e:
            print(f"âœ— æ–‡æœ¬ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
            self.results["æ–‡æœ¬ç”Ÿæˆ"] = {"çŠ¶æ€": "å¤±è´¥", "é”™è¯¯": str(e)}
            return False
    
    def test_visualization(self):
        """æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½"""
        print("\næµ‹è¯•5: å¯è§†åŒ–åŠŸèƒ½")
        print("-" * 40)
        
        try:
            from course.code_examples.moe_routing_demo import SimpleRouter, visualize_routing_patterns
            
            router = SimpleRouter(32, 4)
            input_data = ops.randn(1, 8, 32)
            
            # å¯è§†åŒ–æµ‹è¯•ï¼ˆä¸æ˜¾ç¤ºï¼Œåªä¿å­˜ï¼‰
            print("å¼€å§‹å¯è§†åŒ–æµ‹è¯•...")
            visualize_routing_patterns(router, input_data, "Test Routing Visualization")
            
            print("âœ“ å¯è§†åŒ–æµ‹è¯•é€šè¿‡")
            self.results["å¯è§†åŒ–"] = {"çŠ¶æ€": "é€šè¿‡"}
            return True
            
        except Exception as e:
            print(f"âœ— å¯è§†åŒ–æµ‹è¯•å¤±è´¥: {e}")
            self.results["å¯è§†åŒ–"] = {"çŠ¶æ€": "å¤±è´¥", "é”™è¯¯": str(e)}
            return False
    
    def test_performance(self):
        """æµ‹è¯•æ€§èƒ½"""
        print("\næµ‹è¯•6: æ€§èƒ½åŸºå‡†")
        print("-" * 40)
        
        try:
            config = MistralConfig(
                vocab_size=100,
                hidden_size=128,
                num_hidden_layers=2,
                num_attention_heads=4,
                num_key_value_heads=2,
                head_dim=32,
                intermediate_size=256,
                moe=MoeConfig(num_experts=4, num_experts_per_tok=2)
            )
            
            model = MistralForCausalLM(config)
            model.set_train(False)
            
            # é¢„çƒ­
            warmup_input = ops.randint(0, config.vocab_size, (1, 10))
            for _ in range(3):
                _ = model(warmup_input)
            
            # æ€§èƒ½æµ‹è¯•
            test_input = ops.randint(0, config.vocab_size, (2, 20))
            
            times = []
            for _ in range(5):
                start = time.time()
                _ = model(test_input)
                times.append(time.time() - start)
            
            avg_time = sum(times[1:]) / len(times[1:])  # æ’é™¤ç¬¬ä¸€æ¬¡
            throughput = (2 * 20) / avg_time  # tokens/s
            
            print(f"âœ“ æ€§èƒ½æµ‹è¯•é€šè¿‡")
            print(f"  å¹³å‡æ—¶é—´: {avg_time*1000:.2f}ms")
            print(f"  ååé‡: {throughput:.1f} tokens/s")
            
            self.results["æ€§èƒ½"] = {
                "çŠ¶æ€": "é€šè¿‡", 
                "å¹³å‡æ—¶é—´": f"{avg_time*1000:.2f}ms",
                "ååé‡": f"{throughput:.1f} tokens/s"
            }
            return True
            
        except Exception as e:
            print(f"âœ— æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            self.results["æ€§èƒ½"] = {"çŠ¶æ€": "å¤±è´¥", "é”™è¯¯": str(e)}
            return False
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("=" * 60)
        print("æœ€ç»ˆéªŒè¯æµ‹è¯•å¥—ä»¶")
        print("=" * 60)
        
        tests = [
            self.test_basic_functionality,
            self.test_moe_functionality,
            self.test_moe_routing,
            self.test_generation,
            self.test_visualization,
            self.test_performance
        ]
        
        passed = 0
        total = len(tests)
        
        for test in tests:
            if test():
                passed += 1
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\n" + "=" * 60)
        print("æœ€ç»ˆæµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)
        print(f"é€šè¿‡: {passed}/{total} ({passed/total*100:.1f}%)")
        
        report = {
            "æ€»æµ‹è¯•æ•°": total,
            "é€šè¿‡æ•°": passed,
            "å¤±è´¥æ•°": total - passed,
            "æˆåŠŸç‡": f"{passed/total*100:.1f}%",
            "è¯¦ç»†ç»“æœ": self.results
        }
        
        with open('final_validation_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        if passed == total:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")
            print("âœ… æ¨¡å‹è¿ç§»å’Œä¿®å¤å®Œå…¨æˆåŠŸï¼")
        else:
            print(f"âš ï¸ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        
        print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: final_validation_report.json")
        return passed == total

if __name__ == "__main__":
    validator = FinalValidator()
    success = validator.run_all_tests()
